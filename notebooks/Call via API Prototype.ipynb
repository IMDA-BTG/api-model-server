{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "14afab96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T02:22:29.601144Z",
     "start_time": "2022-05-19T02:22:29.597233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import traceback\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0ec61",
   "metadata": {},
   "source": [
    "# SHAP\n",
    "\n",
    "As we are not supposed to know what model is running in the backend, we can only use KernelSHAP in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857daee",
   "metadata": {},
   "source": [
    "The API server takes in a data file.\n",
    "\n",
    "Our user provides us the data file. SHAP requires the background data (2nd parameter in KernelExplainer) to be an array format.\n",
    "\n",
    "- KernelExplainer will convert the 2nd parameter into numpy.ndarray\n",
    "- This means that if the user uploads a dataframe storing pandas df, then we have to do these\n",
    "    - extract the feature names\n",
    "    - save the given data, and reload the data again, transform it to pandas dataframe and use the feature names as the column\n",
    "    \n",
    "* means that `get_predictions` need to be customized based on the model API server...\n",
    "    - or our tester need to build according to our API specs for the testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd479dda",
   "metadata": {},
   "source": [
    "## Via File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0d002c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T02:49:32.306697Z",
     "start_time": "2022-05-19T02:49:32.231162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id              name     first       last compas_screening_date  \\\n",
      "7153  10920   bradley ecklund   bradley    ecklund            2013-01-11   \n",
      "4341   6621  andres penalopez    andres  penalopez            2013-09-22   \n",
      "1363   2093        deanna dye    deanna        dye            2013-07-29   \n",
      "4526   6916      carl fleming      carl    fleming            2013-02-23   \n",
      "5592   8520    alain williams     alain   williams            2014-04-24   \n",
      "262     384      calvin ellis    calvin      ellis            2014-04-01   \n",
      "2433   3709      tesa edwards      tesa    edwards            2013-04-14   \n",
      "1035   1590       mark harden      mark     harden            2014-03-27   \n",
      "3247   4964     lemy williams      lemy   williams            2014-04-01   \n",
      "4130   6301    epifania roman  epifania      roman            2013-08-24   \n",
      "\n",
      "         sex         dob  age       age_cat              race  ...  \\\n",
      "7153    Male  1981-06-23   34       25 - 45         Caucasian  ...   \n",
      "4341    Male  1988-06-15   27       25 - 45          Hispanic  ...   \n",
      "1363  Female  1983-01-02   33       25 - 45         Caucasian  ...   \n",
      "4526    Male  1992-11-04   23  Less than 25  African-American  ...   \n",
      "5592    Male  1986-12-12   29       25 - 45  African-American  ...   \n",
      "262     Male  1987-01-22   29       25 - 45  African-American  ...   \n",
      "2433  Female  1977-11-17   38       25 - 45  African-American  ...   \n",
      "1035    Male  1972-07-19   43       25 - 45  African-American  ...   \n",
      "3247    Male  1975-09-23   40       25 - 45  African-American  ...   \n",
      "4130    Male  1982-10-10   33       25 - 45  African-American  ...   \n",
      "\n",
      "      v_type_of_assessment  v_decile_score  v_score_text  v_screening_date  \\\n",
      "7153      Risk of Violence               5        Medium        2013-01-11   \n",
      "4341      Risk of Violence               3           Low        2013-09-22   \n",
      "1363      Risk of Violence               1           Low        2013-07-29   \n",
      "4526      Risk of Violence               5        Medium        2013-02-23   \n",
      "5592      Risk of Violence               5        Medium        2014-04-24   \n",
      "262       Risk of Violence               3           Low        2014-04-01   \n",
      "2433      Risk of Violence               1           Low        2013-04-14   \n",
      "1035      Risk of Violence               1           Low        2014-03-27   \n",
      "3247      Risk of Violence               5        Medium        2014-04-01   \n",
      "4130      Risk of Violence               3           Low        2013-08-24   \n",
      "\n",
      "      in_custody  out_custody priors_count.1 start   end event  \n",
      "7153  2015-07-23   2015-07-23              4     1   923     0  \n",
      "4341  2014-10-23   2014-10-24              0     0   396     1  \n",
      "1363  2013-09-14   2013-09-15              0     0    47     0  \n",
      "4526  2013-02-22   2013-03-30              1    35  1133     0  \n",
      "5592  2014-10-12   2014-11-13              6     0   164     1  \n",
      "262   2014-03-31   2014-04-01              1     0   731     0  \n",
      "2433  2013-04-13   2013-04-17              0     3  1083     0  \n",
      "1035  2014-12-30   2015-01-04              0     0   256     1  \n",
      "3247  2014-04-10   2014-04-12              3     0     9     1  \n",
      "4130  2015-01-07   2015-01-07              1     0   500     1  \n",
      "\n",
      "[10 rows x 52 columns]\n",
      "<Response [200]>\n",
      "[0 0 0 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy \n",
    "\n",
    "data = pickle.load(open(\"../data/pickle_scikit_lr_compas_xtest_pkl.sav\", \"rb\")).sample(10)\n",
    "background = pickle.load(open(\"../data/pickle_scikit_lr_compas_xtrain_pkl.sav\", \"rb\")).sample(10)\n",
    "background.columns\n",
    "\n",
    "api_url = \"http://localhost:5000/predict\"\n",
    "column_name = background.columns # this is a hack also\n",
    "\n",
    "def get_predictions(background):\n",
    "    \"\"\"SHAP requires the second parameter to be already in a data form\"\"\"\n",
    "    print(background)\n",
    "    # background is converted into numpy by SHAP\n",
    "    location = \"../data/pickle_scikit_lr_compas_xtrain_pkl.sav.tmp\"\n",
    "    f = open(location, \"wb+\")\n",
    "    \n",
    "    # convert to Pandas, cause that's what the API server can read\n",
    "    \n",
    "    if type(background) == numpy.ndarray:\n",
    "        df = pd.DataFrame(background, columns=column_name)\n",
    "        pickle.dump(df, f)\n",
    "        f.close()\n",
    "    else:\n",
    "        # otherwise we can just use it directly\n",
    "        pickle.dump(background, f)\n",
    "        f.close()\n",
    "    \n",
    "    files = {'file': open(location, \"rb\")}\n",
    "    \n",
    "    r = requests.post(api_url, files=files)\n",
    "    \n",
    "    print(r)\n",
    "    predictions = json.loads(r.content)\n",
    "    \n",
    "    \n",
    "    return numpy.array(predictions[\"response\"])\n",
    "\n",
    "predictions = get_predictions(background)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e1e5c13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T02:49:44.465585Z",
     "start_time": "2022-05-19T02:49:40.714810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10920 'bradley ecklund' 'bradley' 'ecklund' '2013-01-11' 'Male'\n",
      "  '1981-06-23' 34 '25 - 45' 'Caucasian' 0 5 0 0 4 0.0\n",
      "  '2013-01-11 01:39:37' '2013-01-12 03:08:33' '13000503CF10A'\n",
      "  '2013-01-10' nan 1.0 'F' 'Pos Cannabis W/Intent Sel/Del' 0 nan nan nan\n",
      "  nan nan nan nan nan 0 nan nan nan nan 'Risk of Recidivism' 5 'Medium'\n",
      "  '2013-01-11' 'Risk of Violence' 5 'Medium' '2013-01-11' '2015-07-23'\n",
      "  '2015-07-23' 4 1 923 0]\n",
      " [6621 'andres penalopez' 'andres' 'penalopez' '2013-09-22' 'Male'\n",
      "  '1988-06-15' 27 '25 - 45' 'Hispanic' 0 2 0 0 0 0.0\n",
      "  '2013-09-22 03:53:21' '2013-09-22 08:00:54' '13013359CF10A'\n",
      "  '2013-09-21' nan 1.0 'F' 'Grand Theft in the 3rd Degree' 1\n",
      "  '14014299CF10A' '(F3)' 0.0 '2014-10-23'\n",
      "  'Use of Anti-Shoplifting Device' '2014-10-23' '2014-10-24' nan 0 nan\n",
      "  nan nan nan 'Risk of Recidivism' 2 'Low' '2013-09-22'\n",
      "  'Risk of Violence' 3 'Low' '2013-09-22' '2014-10-23' '2014-10-24' 0 0\n",
      "  396 1]\n",
      " [2093 'deanna dye' 'deanna' 'dye' '2013-07-29' 'Female' '1983-01-02' 33\n",
      "  '25 - 45' 'Caucasian' 0 2 0 0 0 -2.0 '2013-07-27 02:32:45'\n",
      "  '2013-07-28 02:02:00' '13014224MM10A' '2013-07-26' nan 3.0 'M'\n",
      "  'Offer Agree Secure For Lewd Act' 0 nan nan nan nan nan nan nan nan 0\n",
      "  nan nan nan nan 'Risk of Recidivism' 2 'Low' '2013-07-29'\n",
      "  'Risk of Violence' 1 'Low' '2013-07-29' '2013-09-14' '2013-09-15' 0 0\n",
      "  47 0]\n",
      " [6916 'carl fleming' 'carl' 'fleming' '2013-02-23' 'Male' '1992-11-04'\n",
      "  23 'Less than 25' 'African-American' 0 6 0 0 1 -1.0\n",
      "  '2013-02-22 09:55:37' '2013-03-30 04:46:32' '13002762CF10A'\n",
      "  '2013-02-22' nan 1.0 'F' 'Grand Theft in the 3rd Degree' 0 nan nan nan\n",
      "  nan nan nan nan nan 0 nan nan nan nan 'Risk of Recidivism' 6 'Medium'\n",
      "  '2013-02-23' 'Risk of Violence' 5 'Medium' '2013-02-23' '2013-02-22'\n",
      "  '2013-03-30' 1 35 1133 0]\n",
      " [8520 'alain williams' 'alain' 'williams' '2014-04-24' 'Male'\n",
      "  '1986-12-12' 29 '25 - 45' 'African-American' 0 6 0 0 6 -1.0\n",
      "  '2014-04-23 02:44:54' '2014-04-24 03:44:57' '14005681CF10A'\n",
      "  '2014-04-23' nan 1.0 'F' 'Felony Driving While Lic Suspd' 1\n",
      "  '14069046TC40A' '(M2)' nan '2014-10-05' 'DWLS Canceled Disqul 1st Off'\n",
      "  nan nan nan 1 '14013798CF10A' '(F3)' '2014-10-12'\n",
      "  'Battery on Law Enforc Officer' 'Risk of Recidivism' 6 'Medium'\n",
      "  '2014-04-24' 'Risk of Violence' 5 'Medium' '2014-04-24' '2014-10-12'\n",
      "  '2014-11-13' 6 0 164 1]\n",
      " [384 'calvin ellis' 'calvin' 'ellis' '2014-04-01' 'Male' '1987-01-22' 29\n",
      "  '25 - 45' 'African-American' 0 3 0 0 1 -1.0 '2014-03-31 02:14:12'\n",
      "  '2014-04-01 01:22:49' '14005495MM10A' '2014-03-31' nan 1.0 'M'\n",
      "  'Battery' 0 nan nan nan nan nan nan nan nan 0 nan nan nan nan\n",
      "  'Risk of Recidivism' 3 'Low' '2014-04-01' 'Risk of Violence' 3 'Low'\n",
      "  '2014-04-01' '2014-03-31' '2014-04-01' 1 0 731 0]\n",
      " [3709 'tesa edwards' 'tesa' 'edwards' '2013-04-14' 'Female' '1977-11-17'\n",
      "  38 '25 - 45' 'African-American' 0 1 0 0 0 -1.0 '2013-04-13 02:34:02'\n",
      "  '2013-04-17 11:11:49' '13005334CF10A' nan '2013-04-13' 1.0 'F'\n",
      "  'arrest case no charge' 0 nan nan nan nan nan nan nan nan 0 nan nan nan\n",
      "  nan 'Risk of Recidivism' 1 'Low' '2013-04-14' 'Risk of Violence' 1\n",
      "  'Low' '2013-04-14' '2013-04-13' '2013-04-17' 0 3 1083 0]\n",
      " [1590 'mark harden' 'mark' 'harden' '2014-03-27' 'Male' '1972-07-19' 43\n",
      "  '25 - 45' 'African-American' 0 1 0 0 0 -1.0 '2014-03-26 05:00:03'\n",
      "  '2014-03-27 08:19:09' '14005244MM10A' '2014-03-26' nan 1.0 'M'\n",
      "  'Battery' 1 '15000453MM10A' '(M1)' nan '2014-12-08' 'Battery' nan nan\n",
      "  nan 1 '15000453MM10A' '(M1)' '2014-12-08' 'Battery'\n",
      "  'Risk of Recidivism' 1 'Low' '2014-03-27' 'Risk of Violence' 1 'Low'\n",
      "  '2014-03-27' '2014-12-30' '2015-01-04' 0 0 256 1]\n",
      " [4964 'lemy williams' 'lemy' 'williams' '2014-04-01' 'Male' '1975-09-23'\n",
      "  40 '25 - 45' 'African-American' 0 8 0 0 3 -1.0 '2014-03-31 03:19:04'\n",
      "  '2014-04-01 01:25:43' '14004493CF10A' '2014-03-31' nan 1.0 'F'\n",
      "  'Fleeing Or Attmp Eluding A Leo' 1 '14017909TC10A' '(M1)' 0.0\n",
      "  '2014-04-10' 'Opert With Susp DL 2nd Offens' '2014-04-10' '2014-04-12'\n",
      "  nan 0 nan nan nan nan 'Risk of Recidivism' 8 'High' '2014-04-01'\n",
      "  'Risk of Violence' 5 'Medium' '2014-04-01' '2014-04-10' '2014-04-12' 3\n",
      "  0 9 1]\n",
      " [6301 'epifania roman' 'epifania' 'roman' '2013-08-24' 'Male'\n",
      "  '1982-10-10' 33 '25 - 45' 'African-American' 0 4 0 0 1 -1.0\n",
      "  '2013-08-23 08:13:02' '2013-08-24 05:16:56' '13011923CF10A'\n",
      "  '2013-08-23' nan 1.0 'F' 'Agg Battery Grt/Bod/Harm' 1 '15000252MM10A'\n",
      "  '(M1)' 1.0 '2015-01-06' 'Possess Cannabis/20 Grams Or Less'\n",
      "  '2015-01-07' '2015-01-07' nan 0 nan nan nan nan 'Risk of Recidivism' 4\n",
      "  'Low' '2013-08-24' 'Risk of Violence' 3 'Low' '2013-08-24' '2015-01-07'\n",
      "  '2015-01-07' 1 0 500 1]]\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                         | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7015 'daniel rosario' 'daniel' 'rosario' '2013-03-09' 'Male'\n",
      "  '1992-12-08' 23 'Less than 25' 'Caucasian' 0 2 0 0 0 0.0\n",
      "  '2013-03-09 05:57:11' '2013-03-10 07:02:54' '13003495CF10A'\n",
      "  '2013-03-09' nan 0.0 'F' 'Poss Unlaw Issue Id' 0 nan nan nan nan nan\n",
      "  nan nan nan 0 nan nan nan nan 'Risk of Recidivism' 2 'Low' '2013-03-09'\n",
      "  'Risk of Violence' 5 'Medium' '2013-03-09' '2013-03-09' '2013-03-10' 0\n",
      "  1 1119 0]]\n",
      "<Response [200]>\n",
      "[[7015 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [7015 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [7015 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [1590 'mark harden' 'mark' ... 0 256 0]\n",
      " [4964 'lemy williams' 'lemy' ... 0 9 0]\n",
      " [6301 'epifania roman' 'epifania' ... 0 500 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▎                             | 1/10 [00:00<00:03,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[[3538 'marvon jemmott' 'marvon' 'jemmott' '2013-12-14' 'Male'\n",
      "  '1995-01-17' 21 'Less than 25' 'African-American' 0 2 0 0 1 -1.0\n",
      "  '2013-12-13 07:02:10' '2013-12-14 01:30:41' '13017261CF10A'\n",
      "  '2013-12-13' nan 1.0 'F' 'Grand Theft in the 3rd Degree' 0 nan nan nan\n",
      "  nan nan nan nan nan 0 nan nan nan nan 'Risk of Recidivism' 2 'Low'\n",
      "  '2013-12-14' 'Risk of Violence' 5 'Medium' '2013-12-14' '2014-11-12'\n",
      "  '2014-12-24' 1 0 333 0]]\n",
      "<Response [200]>\n",
      "[[3538 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [3538 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [3538 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [3538 'marvon jemmott' 'marvon' ... 0 333 0]\n",
      " [3538 'marvon jemmott' 'marvon' ... 0 333 0]\n",
      " [3538 'marvon jemmott' 'marvon' ... 0 333 0]]\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████▌                          | 2/10 [00:00<00:02,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8634 'brian bradley' 'brian' 'bradley' '2013-09-30' 'Male' '1971-05-11'\n",
      "  44 '25 - 45' 'African-American' 0 1 0 0 0 -1.0 '2013-09-29 07:10:37'\n",
      "  '2013-09-30 08:52:46' '13013664CF10A' '2013-09-29' nan 1.0 'F'\n",
      "  'Felony Driving While Lic Suspd' 0 nan nan nan nan nan nan nan nan 0\n",
      "  nan nan nan nan 'Risk of Recidivism' 1 'Low' '2013-09-30'\n",
      "  'Risk of Violence' 1 'Low' '2013-09-30' '2013-09-29' '2013-09-30' 0 0\n",
      "  914 0]]\n",
      "<Response [200]>\n",
      "[[8634 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [8634 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [8634 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [1590 'mark harden' 'mark' ... 0 914 1]\n",
      " [4964 'lemy williams' 'lemy' ... 0 914 1]\n",
      " [6301 'epifania roman' 'epifania' ... 0 914 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████▉                       | 3/10 [00:01<00:02,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[[3697 'adolfo casco' 'adolfo' 'casco' '2013-01-27' 'Male' '1962-01-06'\n",
      "  54 'Greater than 45' 'Caucasian' 0 1 0 0 0 -1.0 '2013-01-26 07:42:36'\n",
      "  '2013-01-27 01:56:31' '13001884MM10A' '2013-01-26' nan 1.0 'M'\n",
      "  'Battery' 0 nan nan nan nan nan nan nan nan 0 nan nan nan nan\n",
      "  'Risk of Recidivism' 1 'Low' '2013-01-27' 'Risk of Violence' 2 'Low'\n",
      "  '2013-01-27' '2013-01-26' '2013-01-27' 0 0 1160 0]]\n",
      "<Response [200]>\n",
      "[[3697 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [3697 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [3697 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [3697 'adolfo casco' 'mark' ... 0 256 0]\n",
      " [3697 'adolfo casco' 'lemy' ... 0 9 0]\n",
      " [3697 'adolfo casco' 'epifania' ... 0 500 0]]\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████▏                   | 4/10 [00:01<00:02,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6383 'william walker' 'william' 'walker' '2013-12-23' 'Male'\n",
      "  '1960-05-10' 55 'Greater than 45' 'Caucasian' 0 1 0 0 0 -1.0\n",
      "  '2013-12-22 12:42:17' '2013-12-22 01:00:00' '13023553MM10A'\n",
      "  '2013-12-21' nan 2.0 'M' 'Battery' 1 '14009604CF10A' '(F3)' 0.0\n",
      "  '2014-07-14' 'Felony Battery (Dom Strang)' '2014-07-14' '2014-07-17'\n",
      "  nan 1 '14009604CF10A' '(F3)' '2014-07-14' 'Felony Battery (Dom Strang)'\n",
      "  'Risk of Recidivism' 1 'Low' '2013-12-23' 'Risk of Violence' 1 'Low'\n",
      "  '2013-12-23' '2014-07-14' '2014-07-17' 0 0 203 1]]\n",
      "<Response [200]>\n",
      "[[6383 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [6383 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [6383 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [1590 'mark harden' 'mark' ... 0 256 1]\n",
      " [4964 'lemy williams' 'lemy' ... 0 9 1]\n",
      " [6301 'epifania roman' 'epifania' ... 0 500 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████▌                | 5/10 [00:01<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[[1150 'wanda daniels' 'wanda' 'daniels' '2013-10-09' 'Female'\n",
      "  '1968-12-18' 47 'Greater than 45' 'African-American' 0 10 0 0 19 -1.0\n",
      "  '2013-10-08 12:12:30' '2013-11-08 08:59:42' '13014107CF10A'\n",
      "  '2013-10-08' nan 1.0 'F' 'Possession of Cocaine' 1 '15012442CF10A'\n",
      "  '(F3)' 0.0 '2015-09-25' 'Possession of Cocaine' '2015-09-25'\n",
      "  '2015-10-30' nan 0 nan nan nan nan 'Risk of Recidivism' 10 'High'\n",
      "  '2013-10-09' 'Risk of Violence' 2 'Low' '2013-10-09' '2014-01-28'\n",
      "  '2014-07-02' 19 30 111 0]]\n",
      "<Response [200]>\n",
      "[[1150 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [1150 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [1150 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [1590 'wanda daniels' 'wanda' ... 0 111 1]\n",
      " [4964 'wanda daniels' 'wanda' ... 0 111 1]\n",
      " [6301 'wanda daniels' 'wanda' ... 0 111 1]]\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████▊             | 6/10 [00:02<00:01,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6359 'terry bradley' 'terry' 'bradley' '2013-12-18' 'Male' '1961-08-18'\n",
      "  54 'Greater than 45' 'African-American' 0 6 0 0 3 -1.0\n",
      "  '2013-12-17 02:05:51' '2013-12-19 09:10:18' '13016923CF10A' nan\n",
      "  '2013-12-17' 1.0 'F' 'arrest case no charge' 1 '14006976TC10A' '(M2)'\n",
      "  1.0 '2014-02-23' 'Susp Drivers Lic 1st Offense' '2014-02-24'\n",
      "  '2014-02-28' nan 0 nan nan nan nan 'Risk of Recidivism' 6 'Medium'\n",
      "  '2013-12-18' 'Risk of Violence' 3 'Low' '2013-12-18' '2013-12-17'\n",
      "  '2013-12-19' 3 1 67 1]]\n",
      "<Response [200]>\n",
      "[[6359 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [6359 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [6359 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [6359 'terry bradley' 'terry' ... 1 67 1]\n",
      " [6359 'terry bradley' 'terry' ... 1 67 1]\n",
      " [6359 'terry bradley' 'terry' ... 1 67 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████          | 7/10 [00:02<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[[2464 'ronald shelton' 'ronald' 'shelton' '2013-05-29' 'Male'\n",
      "  '1958-06-02' 57 'Greater than 45' 'African-American' 0 9 0 0 12 -1.0\n",
      "  '2013-05-28 08:29:39' '2013-07-18 03:49:07' '13007619CF10A'\n",
      "  '2013-05-28' nan 1.0 'F' 'Possession of Cocaine' 0 nan nan nan nan nan\n",
      "  nan nan nan 0 nan nan nan nan 'Risk of Recidivism' 9 'High'\n",
      "  '2013-05-29' 'Risk of Violence' 6 'Medium' '2013-05-29' '2013-05-28'\n",
      "  '2013-07-18' 12 50 1038 0]]\n",
      "<Response [200]>\n",
      "[[2464 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [2464 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [2464 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [1590 'ronald shelton' 'mark' ... 0 256 1]\n",
      " [4964 'ronald shelton' 'lemy' ... 0 9 1]\n",
      " [6301 'ronald shelton' 'epifania' ... 0 500 1]]\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████▍      | 8/10 [00:02<00:00,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8309 'andrae cray' 'andrae' 'cray' '2013-10-23' 'Male' '1990-03-08' 26\n",
      "  '25 - 45' 'African-American' 0 5 1 0 6 -8.0 '2013-10-15 07:14:52'\n",
      "  '2013-10-17 05:10:33' '12015557TC10A' nan '2013-10-15' 8.0 'M'\n",
      "  'arrest case no charge' 0 nan nan nan nan nan nan nan nan 0 nan nan nan\n",
      "  nan 'Risk of Recidivism' 5 'Medium' '2013-10-23' 'Risk of Violence' 4\n",
      "  'Low' '2013-10-23' '2015-07-17' '2015-08-01' 6 0 632 0]]\n",
      "<Response [200]>\n",
      "[[8309 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [8309 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [8309 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [8309 'andrae cray' 'andrae' ... 0 256 0]\n",
      " [8309 'andrae cray' 'andrae' ... 0 9 0]\n",
      " [8309 'andrae cray' 'andrae' ... 0 500 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████████▋   | 9/10 [00:03<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[[9784 'sheldon jones' 'sheldon' 'jones' '2013-04-22' 'Male' '1976-05-18'\n",
      "  39 '25 - 45' 'African-American' 0 2 0 0 2 -1.0 '2013-04-21 04:21:02'\n",
      "  '2013-04-22 06:59:21' '13007676MM10A' '2013-04-21' nan 1.0 'M'\n",
      "  'Driving Under The Influence' 0 nan nan nan nan nan nan nan nan 0 nan\n",
      "  nan nan nan 'Risk of Recidivism' 2 'Low' '2013-04-22'\n",
      "  'Risk of Violence' 1 'Low' '2013-04-22' '2013-04-21' '2013-04-22' 2 0\n",
      "  1075 0]]\n",
      "<Response [200]>\n",
      "[[9784 'bradley ecklund' 'bradley' ... 1 923 0]\n",
      " [9784 'andres penalopez' 'andres' ... 0 396 1]\n",
      " [9784 'deanna dye' 'deanna' ... 0 47 0]\n",
      " ...\n",
      " [1590 'mark harden' 'mark' ... 0 1075 0]\n",
      " [4964 'lemy williams' 'lemy' ... 0 1075 0]\n",
      " [6301 'epifania roman' 'epifania' ... 0 1075 0]]\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 10/10 [00:03<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.27356538e-02 -7.43594984e-03  0.00000000e+00  1.54058109e-02\n",
      "  -5.35473679e-03  1.13654280e-01  0.00000000e+00 -1.19344646e-02\n",
      "   5.86539007e-01 -2.47427403e-01  0.00000000e+00  7.92084593e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -9.05862607e-03  4.70622472e-03  0.00000000e+00\n",
      "  -4.19535758e-03  9.47130490e-03  1.59155460e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -3.76068746e-03  0.00000000e+00\n",
      "   8.78681025e-03  0.00000000e+00 -6.18149507e-03 -1.25023695e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -3.94267913e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.47791001e-03 -1.00691002e-02\n",
      "   7.04014246e-03 -6.03058055e-03  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  7.52670700e-02  0.00000000e+00  0.00000000e+00\n",
      "   2.77994004e-01  1.22769363e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.22319137e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   6.46212587e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00421430e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.30918146e-01  2.62492350e-04  0.00000000e+00\n",
      "   0.00000000e+00  2.32706334e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.59017048e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  2.32141273e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  9.63924121e-04  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   4.64918558e-05  3.05022017e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   8.17356556e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  2.48789055e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.07332946e-03  2.49701490e-02 -3.78299594e-03  0.00000000e+00\n",
      "  -1.72684033e-01 -1.25620315e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.20809476e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.33316842e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  2.70511087e-02  0.00000000e+00  0.00000000e+00\n",
      "  -1.69367359e-01 -1.24298728e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -2.52922353e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -1.25266804e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.25582615e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.15734605e-01  0.00000000e+00  0.00000000e+00\n",
      "  -3.15864728e-01  7.07176775e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -4.70119417e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.13821310e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -5.79928139e-03  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.77281211e-02  0.00000000e+00  0.00000000e+00\n",
      "  -6.73417809e-01  1.06009362e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.48642669e-03  0.00000000e+00  1.05410418e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.78348078e-03  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  6.00823170e-02  0.00000000e+00  0.00000000e+00\n",
      "  -6.77588917e-01  1.08738777e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.08767823e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.00000000e-02  0.00000000e+00  0.00000000e+00\n",
      "  -5.00000000e-02  1.00000000e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -5.00000000e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  4.82645094e-02  0.00000000e+00  0.00000000e+00\n",
      "  -4.98007712e-02  9.93805901e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -4.97844328e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "explainer = shap.KernelExplainer(get_predictions, background)\n",
    "print(explainer.shap_values(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ad5fe",
   "metadata": {},
   "source": [
    "## Via processed data using single datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f32267c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T03:39:59.553855Z",
     "start_time": "2022-05-19T03:39:59.471825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 10/10 [00:00<00:00, 163.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [1]}\n",
      "{'response': [0, 0, 0, 0, 0, 0]}\n",
      "{'response': [0]}\n",
      "{'response': [0, 0]}\n",
      "{'response': [0]}\n",
      "{'response': [0]}\n",
      "{'response': [0, 0]}\n",
      "{'response': [1]}\n",
      "{'response': [0, 1, 1, 0, 0, 1]}\n",
      "{'response': [1]}\n",
      "{'response': [0, 0, 0, 0, 0, 0]}\n",
      "{'response': [0]}\n",
      "{'response': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'response': [0]}\n",
      "{'response': [0]}\n",
      "{'response': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'response': [0]}\n",
      "{'response': [0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.33333333,  0.        ,  0.        ,  0.33333333,  0.33333333],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],\n",
       "       [ 0.33333333,  0.        ,  0.        ,  0.33333333,  0.33333333],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.08333333,  0.        , -0.25      ,  0.08333333,  0.08333333],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy \n",
    "from json import JSONEncoder\n",
    "\n",
    "api_url = \"http://localhost:5000/predict_all\"\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "def get_one_prediction(data):\n",
    "    \"\"\"SHAP requires the second parameter to be already in a data form\"\"\"\n",
    "    # convert the data to payload that can be understood by the API\n",
    "    if type(data) != numpy.ndarray:\n",
    "        data = data.to_numpy()\n",
    "    \n",
    "    data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "    r = requests.post(api_url, json={\"input\": data})\n",
    "    predictions = json.loads(r.content)\n",
    "    print(predictions)\n",
    "    return numpy.array(predictions[\"response\"])\n",
    "\n",
    "# assuming the test upload both data and background to us\n",
    "background = pickle.load(open(\"../data/pickle_pandas_tabular_compas_training.sav\", \"rb\")).drop(\"two_year_recid\", axis=1).sample(1)\n",
    "data = pickle.load(open(\"../data/pickle_pandas_tabular_compas_testing.sav\", \"rb\")).drop(\"two_year_recid\", axis=1).sample(10)\n",
    "\n",
    "explainer = shap.KernelExplainer(get_one_prediction, background)\n",
    "explainer.shap_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a0de2",
   "metadata": {},
   "source": [
    "## Via processed data using multiple datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "56aa0041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T02:42:29.248982Z",
     "start_time": "2022-05-19T02:42:29.243551Z"
    }
   },
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"../model/pickle_scikit_lr_compas.sav\", \"rb\"))\n",
    "predictions = model.predict(background)\n",
    "print(predictions)\n",
    "e = shap.KernelExplainer(model.predict_proba, background)\n",
    "e.shap_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "60cd8a62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T03:41:23.096290Z",
     "start_time": "2022-05-19T03:41:23.037260Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 5/5 [00:00<00:00, 126.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.18333333,  0.        ,  0.01666667, -0.21666667,  0.01666667],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.16666667,  0.        ,  0.06666667,  0.03333333, -0.26666667],\n",
       "       [-0.03333333, -0.03333333,  0.        ,  0.06666667,  0.        ],\n",
       "       [-0.025     ,  0.05833333,  0.125     ,  0.73333333,  0.10833333]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy \n",
    "from json import JSONEncoder\n",
    "\n",
    "api_url = \"http://localhost:5000/predict_all\"\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "def get_multiple_prediction(data):\n",
    "    \"\"\"SHAP requires the second parameter to be already in a data form\"\"\"\n",
    "    # convert the data to payload that can be understood by the API\n",
    "    if type(data) != numpy.ndarray:\n",
    "        data = data.to_numpy()\n",
    "    \n",
    "    data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "    #print({\"input\": [[1, 1, 1, 1, 1]]})\n",
    "    r = requests.post(api_url, json={\"input\": data})\n",
    "    predictions = json.loads(r.content)\n",
    "    #print(predictions)\n",
    "    return numpy.array(predictions[\"response\"])\n",
    "\n",
    "# assuming the test upload both data and background to us\n",
    "background = pickle.load(open(\"../data/pickle_pandas_tabular_compas_training.sav\", \"rb\")).drop(\"two_year_recid\", axis=1).sample(10)\n",
    "data = pickle.load(open(\"../data/pickle_pandas_tabular_compas_testing.sav\", \"rb\")).drop(\"two_year_recid\", axis=1).sample(5)\n",
    "\n",
    "explainer = shap.KernelExplainer(get_multiple_prediction, background)\n",
    "explainer.shap_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74023c7",
   "metadata": {},
   "source": [
    "# AIF360\n",
    "\n",
    "This is straightforward, we can the prediction, we have the ground truth.. so we can compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "faf6aa41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T09:59:53.227736Z",
     "start_time": "2022-05-18T09:59:53.224777Z"
    }
   },
   "outputs": [],
   "source": [
    "from aif360.datasets import CompasDataset, BinaryLabelDataset\n",
    "from aif360.datasets.multiclass_label_dataset import MulticlassLabelDataset\n",
    "from aif360.metrics import DatasetMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# Fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2b39b406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T09:59:47.924340Z",
     "start_time": "2022-05-18T09:59:47.771966Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = pickle.load(open(\"../data/pickle_scikit_lr_compas_ytest_pkl.sav\", \"rb\"))\n",
    "x_test = pickle.load(open(\"../data/pickle_scikit_lr_compas_xtest_pkl.sav\", \"rb\"))\n",
    "y_train = pickle.load(open(\"../data/pickle_scikit_lr_compas_ytrain_pkl.sav\", \"rb\"))\n",
    "x_train = pickle.load(open(\"../data/pickle_scikit_lr_compas_xtrain_pkl.sav\", \"rb\"))\n",
    "\n",
    "def get_prediction_fairness(location):\n",
    "    files = {'file': open(location, \"rb\")}\n",
    "    r = requests.post(api_url, files=files)\n",
    "    predictions = json.loads(r.content)\n",
    "    return numpy.array(predictions[\"response\"])\n",
    "\n",
    "location = \"../data/pickle_scikit_lr_compas_xtest_pkl.sav\"\n",
    "predictions = get_prediction_fairness(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a908d8",
   "metadata": {},
   "source": [
    "## Issue using AIF360 without Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a01b68",
   "metadata": {},
   "source": [
    "\n",
    "*AIF360 requires the data to be processed before it can be placed in the binarylabeldataset.\n",
    "\n",
    "*we are not expecting to process the data if we are moving to call the model via API, hence, we might not not be able to use AIF360 directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "94ca8736",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T03:52:13.086666Z",
     "start_time": "2022-05-19T03:52:13.055409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id               name      first     last compas_screening_date  \\\n",
      "5396  8223  christina deperna  christina  deperna            2013-08-04   \n",
      "\n",
      "         sex         dob  age  age_cat       race  ...  v_decile_score  \\\n",
      "5396  Female  1984-10-07   31  25 - 45  Caucasian  ...               5   \n",
      "\n",
      "      v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
      "5396        Medium        2013-08-04  2013-08-04   2013-08-05              14   \n",
      "\n",
      "     start  end event two_year_recid  \n",
      "5396     1  971     0              0  \n",
      "\n",
      "[1 rows x 53 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input DataFrames cannot contain NA values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1892/1674288320.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msensitive_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m original_data = BinaryLabelDataset(df=x_train,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                     \u001b[0mlabel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     protected_attribute_names=sensitive_features)\n",
      "\u001b[0;32m/mnt/d/repo/env/lib/python3.8/site-packages/aif360/datasets/binary_label_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, favorable_label, unfavorable_label, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfavorable_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfavorable_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryLabelDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/repo/env/lib/python3.8/site-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[1;32m     92\u001b[0m                             \"the data (features, labels, protected attributes)\")\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input DataFrames cannot contain NA values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input DataFrames cannot contain NA values."
     ]
    }
   ],
   "source": [
    "ground_truth = \"two_year_recid\"\n",
    "\n",
    "x_train[ground_truth] = y_train[ground_truth]\n",
    "sensitive_features = [\"sex\"]\n",
    "print(x_train.head(1))\n",
    "original_data = BinaryLabelDataset(df=x_train,\n",
    "                                    label_names=[ground_truth],  # ground truth\n",
    "                                    protected_attribute_names=sensitive_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fcef5d",
   "metadata": {},
   "source": [
    "# ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ebe02685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T03:57:56.949682Z",
     "start_time": "2022-05-19T03:57:56.946950Z"
    }
   },
   "outputs": [],
   "source": [
    "from art.attacks.evasion import ZooAttack\n",
    "from art.estimators.classification import SklearnClassifier, XGBoostClassifier, BlackBoxClassifier\n",
    "from art.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8527466d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T04:02:23.932615Z",
     "start_time": "2022-05-19T04:02:22.943555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|█████████████████████████████| 5/5 [00:00<00:00,  5.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 1, 1],\n",
       "       [0, 0, 2, 2, 1],\n",
       "       [0, 0, 0, 4, 1],\n",
       "       [0, 0, 2, 0, 0],\n",
       "       [2, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy \n",
    "from json import JSONEncoder\n",
    "\n",
    "api_url = \"http://localhost:5000/predict_all\"\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "\n",
    "def get_multiple_prediction(data):\n",
    "    \"\"\"SHAP requires the second parameter to be already in a data form\"\"\"\n",
    "    # convert the data to payload that can be understood by the API\n",
    "    if type(data) != numpy.ndarray:\n",
    "        data = data.to_numpy()\n",
    "    \n",
    "    data = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "    #print({\"input\": [[1, 1, 1, 1, 1]]})\n",
    "    r = requests.post(api_url, json={\"input\": data})\n",
    "    predictions = json.loads(r.content)\n",
    "    \n",
    "    return to_categorical(numpy.array(predictions[\"response\"]), nb_classes=2)\n",
    "\n",
    "# assuming the test upload both data and background to us\n",
    "background = pickle.load(open(\"../data/pickle_pandas_tabular_compas_training.sav\", \"rb\")).drop(\"two_year_recid\", axis=1).sample(10)\n",
    "data = pickle.load(open(\"../data/pickle_pandas_tabular_compas_testing.sav\", \"rb\")).drop(\"two_year_recid\", axis=1).sample(5)\n",
    "\n",
    "classifier = BlackBoxClassifier(predict_fn=get_multiple_prediction, nb_classes=2,\n",
    "                                                input_shape=data.to_numpy()[0].shape)\n",
    "\n",
    "zoo = ZooAttack(classifier=classifier, confidence=0.0, targeted=False, learning_rate=1e-1, max_iter=20,\n",
    "                            binary_search_steps=10, initial_const=1e-3, abort_early=True, use_resize=False,\n",
    "                            use_importance=False, nb_parallel=1, batch_size=1, variable_h=0.2)\n",
    "\n",
    "adv_samples = zoo.generate(data.to_numpy()) # this requires numpy data\n",
    "adv_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
